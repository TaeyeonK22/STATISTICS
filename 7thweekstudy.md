# 통계학 7주차 정규과제

📌통계학 정규과제는 매주 정해진 분량의 『*데이터 분석가가 반드시 알아야 할 모든 것*』 을 읽고 학습하는 것입니다. 이번 주는 아래의 **Statistics_7th_TIL**에 나열된 분량을 읽고 `학습 목표`에 맞게 공부하시면 됩니다.

아래의 문제를 풀어보며 학습 내용을 점검하세요. 문제를 해결하는 과정에서 개념을 스스로 정리하고, 필요한 경우 추가자료와 교재를 다시 참고하여 보완하는 것이 좋습니다.

7주차는 `3부. 데이터 분석하기`를 읽고 새롭게 배운 내용을 정리해주시면 됩니다.


## Statistics_7th_TIL

### 3부. 데이터 분석하기
### 13.머신러닝 분석 방법론
### 14.모델 평가



## Study Schedule

|주차 | 공부 범위     | 완료 여부 |
|----|----------------|----------|
|1주차| 1부 p.2~56     | ✅      |
|2주차| 1부 p.57~79    | ✅      | 
|3주차| 2부 p.82~120   | ✅      | 
|4주차| 2부 p.121~202  | ✅      | 
|5주차| 2부 p.203~254  | ✅      | 
|6주차| 3부 p.300~356  | ✅      | 
|7주차| 3부 p.357~615  | ✅      | 

<!-- 여기까진 그대로 둬 주세요-->

# 13.머신러닝 분석 방법론

```
✅ 학습 목표 :
* 선형 회귀와 다항 회귀를 비교하고, 데이터를 활용하여 적절한 회귀 모델을 구축할 수 있다. 
* 로지스틱 회귀 분석의 개념과 오즈(Odds)의 의미를 설명하고, 분류 문제에 적용할 수 있다.
* k-means 알고리즘의 원리를 설명하고, 적절한 군집 개수를 결정하여 데이터를 군집화할 수 있다.
```

## 13.1. 선형 회귀분석과 Elastic Net(예측모델)
<!-- 새롭게 배운 내용을 자유롭게 정리해주세요.-->
<!-- `13.1.3. Ridge와 Lasso 그리고 Elastic Net` 부분은 제외하고 학습하셔도 무방합니다.-->
### 13.1.1. 회귀분석의 기원과 원리
- 회귀분석 용어의 기원과 원리
  - 기원<br>: 프랜시스 골턴이 부모와 자식의 키에 대한 유전 법칙을 연구하다 시작됐다. 사람들의 키는 결국 모집단의 평균으로 회귀한다는 '평균으로의 회귀' 이론의 경험적 연구로 회귀분석은 시작되었다.
  - 원리
    - X, Y 좌표에 산점도를 찍고 X와 Y의 관계를 가장 잘 나타낼 수 있는 직선을 찾음으로써 회귀분석 모델이 만들어진다.
    - 즉, 회귀분석은 해당 객체가 소속된 집단의 X(종속변수) 평균값을 통해 Y(종속변수) 값을 예측하는 것이 기본적인 원리다.
    - 물론 직선이기 때문에 오차가 생길 수 있다. 이러한 오차를 최소화하여 그은 선이 회귀선이다.
    - 회귀분석을 한 마디로 정의하면, "종속변수 Y의 값에 영향을 주는 독립변수 X들의 조건을 고려하여 구한 평균값"이라고 할 수 있다.
  - 구성요소: 절편, 기울기, 오차항
    - 오차항은 독립변수가 종속변수에 주는 영향력을 제외한 변화량을 뜻한다. 회귀분석은 이 오차항을 최소화하는 절편과 기울기를 구하는 것이다.

- 최적의 회귀선을 구하는 방법<br>: 최소제곱추정법(Least square estimation): 회귀선과 각 관측치를 뜻하는 점과의 거리를 최소화하는 것이다. 보다 정확히 말하면 회귀선을 구하기 위해 잔차제곱합(RSS)을 최소화하는 알파와 베타의 값을 찾는 것을 의미한다. 이것은 최대우도추정법으로써 변수가 주어졌을 때 예측값이 관측될 가능도를 최대화하는 것이 곧 오류의 제곱합을 최소화하는 것과 동일한 것이다.

- 단순 회귀분석과 다중 회귀 분석
  - 독립변수가 하나인 회귀분석은 단순 회귀분석, 혹은 단변량 회귀분석이라고 한다.
  - 독립변수가 두 개 이상이면 다중 회귀 분석 혹은 다변량 회귀분석이라고 한다.
    - 다중 회귀분석을 할 때는 독립변수 간 상관관계가 없어아 하므로, 다중공선성 검사를 수행해야 한다. 독립 변수 간에 다중공선성이 없는 상태를 독립성이 있다고 한다. 
    - 이는 상관분석, VIF값 확인 등을 통해 다중공선성을 확인하고, 차원축소나 변수 가공을 통해 이를 방지할 수 있다.

- 회귀 분석이 충족해야 할 기본적인 조건
  - 잔차의 정규성: 독립변수에 해당되는 종속변수의 값들의 잔차는 정규분포를 따라야 한다. 
    - 잔차의 정규성을 확인하기 위해서는 일반적으로 잔차의 히스토그램을 그리거나, Q-Q Plot을 통해 잔차를 정규 분포의 확률 분포와 비교하여 그래프로 표현하는 방법이 있다. Q-Q Plot이 대략적으로 직선 형태를 보일 때 잔차의 정규성을 따른다고 한다. 보다 명확하게 수치적으로 판단하기 위해서는 샤피로-윌크 검정이나 앤더슨-달링검정을 사용한다.
  - 잔차의 등분산성: 잔차의 분산은 회귀 모형의 독립 변숫값과 상관없이 일정해야 한다.
  - 독립성: 독립변수들 간에 상관관계가 없어야 한다.(다중회귀)
  - 선형성: 독립변수 값의 변화에 따른 종속변수 값의 변화는 일정해야 한다.

- 회귀분석의 한계
  - 회귀분석의 회귀선은 선형으로 되어 있기 때문에 독립변수와 종속변수가 비선형적 관계일 경우 예측력이 떨어지는 문제가 발생한다. 이러한 비선형적인 관계를 회귀분석 하기 위해서는, 변수를 구간화하여 이항변수로 표시된 몇 개의 더미변수로 변환하여 분석하면 된다.
  - 또는 비선형성이 심하지 않은 경우, 독립변수나 종속변수에 로그함수를 이용하여 치환하면 비선형성을 어느 정도 완화시킬 수 있다.

### 13.1.2. 다항 회귀
- 다항 회귀의 등장
  - 독립변수들과 종속변수의 관계가 곡선의 관계를 가진 경우의 일반 회귀모델 변수 가공 방식은 한계가 있따. 그래서 고안된 모델이 다항 회귀이다. 
  - 다항회귀란 독립변수와 종속변수의 관계가 곡선형 관계일 때 변수에 각 특성의 제곱을 추가하여 회귀선을 곡선형으로 변환하는 모델이다.
  - 다만 다항회귀는 차수가 커질수록 편향(bias)은 감소하지만 변동성(variance)는 증가하게 된다. 따라서 분산이 늘어나고 과적합을 유발할 수 있다.

### 회귀 분석 변수별 결과

- 변수별 결과 요약 해석법법
  -  Parameter Estimate는 각 변수의 계수(coefficient)를 뜻한다. X1의 계수가 0.604라는 것은, 독립변수 X1의 값이 1씩 커질 때마다 종속변수 Y값이 0.604만큼 커진다는 것을 의미한다. 
  - Intercept는 절편을 의미하므로, 종속변수의 기본값을 의미한다.
  - Standard error는 표준오차로, 이 값이 크다는 것은 그만큼 예측값과 실제값의 차이가 크다는 것이다. 하지만 변수마다 스케일 단위가 다르기 때문에 표준오차의 절대값만으로는 실제 오차가 큰지 판단하기 어렵다. 그래서 사용하는 값이 T Value이다.
  - T Value는 노이즈 대비 시그널의 강도라고 할 수 있다. 즉, 독립변수와 종속변수 간에 선형관계가 얼마나 강한지를 나타내기 때문에, 값이 커야 한다. 계숫값을 표준오차로 나누어 구할 수 있다. 관측치 100개 기준으로 T Value 절댓값이 1.98을 넘으면 0.05 유의수준 임계치를 넘어서기 때문에 유의하다고 판단할 수 있다.
  - T Value와 관측치의 수를 일일이 조합해서 유의도를 판단하는 것은 비효율적이기 때문에 P Value를 사용한다. 유의도를 나타내는 P Value는 T Value와 관측치 수에 의해 결정되는 값이다. 일반적으로 0.05 이하의 값인 경우에 95% 귀무가설 기각역에 포함하므로 해당 변수가 유의하다고 판단하며, 경우에 따라 0.1이나 0.01의 기준을 사용하기도 한다.
  - 다중공선성을 판단할 수 있는 Tolerance와 VIF는 공차한계와 분산팽창지수를 뜻한다. 이들은 해당 변수의 다른 독립변수들과의 상관관계 수준을 판단하는 기준이다. Tolerance의 역수를 취한 값이 VIF 값이기 때문에 하나의 값만 보고 판단해도 무관하다. 

- 다중공선성을 방지하기 위한 변수 선택법
  - 전진 선택법
    - 가장 단순한 선택법으로, 유의미한 독립변수 순으로 하나씩 추가해 나가는 방법이다.
    - 이전 변수 집합에 비해 새로운 변수를 추가했을 때 모델 적합도가 기준치 이상 증가하지 못했을 때 변수선택이 종료된다.
    - 알고리즘이 단순하기 때문에 빠르다는 장점이 있지만 한 번 선택된 변수는 다시 제거되지 않는다.
  - 후진 제거법
    - 모든 독립변수가 포함된 상태에서 시작하여 유의미하지 않은 순으로 설명변수를 하나씩 제거하는 방법이다. 기존 변수 집합에서 어느 한 변수를 제거했을 때, 모델 적합도가 기준치 이상 감소하는 경우에 더 이상 변수를 제거하지 않는다.
    - 전진 선택법과 마찬가지로 한 번 제거된 변수는 다시 추가되지 않는다.
    - 시간이 다소 오래 걸릴 수 있지만, 유의미한 변수를 처음부터 모두 넣고 시작하기 때문에 안전한 방법이다.
  - 단계적 선택법
    - 전진 선택법과 후진 제거법의 단점을 더한 방법이다.
    - 처음에는 전진 선택법과 같이 변수를 하나씩 추가하기 시작하면서, 선택된 변수가 3개 이상이면 변수 추가와 제거를 번갈아 가면서 수행한다. 
    - 단계적 선택법은 단순히 종속변수와의 상관도가 높은 독립변수를 선택하는 것에서 더 나아가, 선택된 독립변수 모델의 잔차를 구하여 선택되지 않은 나머지 변수와 잔차의 상관도를 구하여 변수를 선택한다. 때문에 다른 방법보다 최적의 변수 조합을 찾아낼 가능성이 높다.
    - 그 밖에 단계적 선택법 알고리즘을 개선한 LARS, 변수의 조합에 약간의 우연적 요소를 가미한 변화를 준 유전 알고리즘 등이 있다. 
    - 하지만 최근에는 변수 계수에 가중치를 주어 편향을 허용함으로써 예측 정밀도를 향상시킬 수 있는 Ridge와 Lasso를 조합한 Elastic Net을 사용하는 경우가 많다.

## 13.2. 로지스틱 회귀분석 (분류모델)
<!-- 새롭게 배운 내용을 자유롭게 정리해주세요.-->
- 로지스틱 회귀분석의 기능
  - 로지스틱 회귀분석은 선형회귀분석과 유사하지만 종속변수가 양적척도가 아닌 질적척도라는 차이가 있다. 즉, 로지스틱 회귀분석은 특정 수치를 예측하는 것이 아니라 어떤 카테고리에 들어갈지 분류를 하는 모델이다.
  - 기본 모형은 종속변수가 0과 1이라는 이항(binary)으로 이루어져 예측한다. 만약 종속변수의 범주가 3개 이상일 경우에는 다항 로지스틱 회귀분석을 통해 분류 예측을 할 수 있다.

- 기본 이항 로지스틱 회귀분석
  - 로지스틱 회귀는 기존의 선형회귀식의 사상은 그대로 유지하되 종속변수를 1이 될 확률로 변환하여 그 확률에 따라 0과 1의 여부를 예측한다. 
  - 오즈와 로짓 변환
    - 선형 회귀선은 이항으로 이루어진 종속변수를 직선으로 표현하려다 보니 확률이 양과 음의 무한대로 뻗어나가 버린다. 이러한 방식은 확률을 표현하기에 적합하지 않기 때문에 0과 1 사이의 S자 곡선의 형태를 갖도록 변환해줘야 한다. 단순하게 이야기하면, 종속변수의 값을 1이 될 확률이라 정의하고 값이 0.5보다 크면 1, 0.5보다 작으면 0으로 분류하는 것이다. 물론 분류하는 기준값은 상황에 따라 달라질 수 있다.
    - 로짓 회귀선으로 변환해주기 위해서는 우선 오즈 값을 구해야 한다. 오즈란 사건이 발생할 가능성이 발생하지 않을 가능성보다 어느 정도 큰지를 나타내는 값이다. 분모는 사건이 발생하지 않을 확률, 분자는 사건이 발생할 확률로 하여 비율로 나타낸다. 즉, 발생 확률이 그렇지 않을 확률과 같으면 1.0이고, 발생 확률이 60%이고 발생하지 않을 확률이 40%라면 오즈는 1.5가 된다.
    - 이렇게 직선 형태의 회귀 값을 사건이 일어날 오즈 값으로 변환하게 되면 분류 모델에 가까워진 것 같은 느낌이 든다. 그런데 발생 확률이 1에 가까웢리수록 오즈 값은 기하급수적으로 커지고 최솟값은 0이 된다. 즉, 0부터 무한대에 가깝게 치솟는 균형 잡히지 못한 형태를 갖게 된다.
    - 그래서 오즈 값에 로그를 취하면 양의 무한대에서 음의 무한대를 갖는 형태가 된다. 이렇게 로그를 취해 확률의 범위를 표현할 수 있다. 하지만 여전히 0에서 1 사이의 범위를 나타내지 못하는 문제가 있다. 그래서 확률을 로짓 변환하여 0에서 1 사이로 치환해 준다. 이러한 변환식을 시그모이드 함수라고 하는데, 뉴럴네트워크의 이항 분류에도 활용되는 유용한 함수이다.
  - 이렇게 로지스틱 회귀분석은 확률을 0에서 1 사이로 변환해서 표현한다. 이러한 분류 모델은 카테고리를 분류하는 임계치를 어떻게 설정하는지가 중요하다. 기본적으로는 분류 기준값이 0.5이지만, 어떤 주제의 모델인가에 따라 임계치 기준은 달라질 수 있다. 최적의 효율을 따져가며 분류 기준을 잡아야 하기 때문에, 로지스틱 회귀 모델과 같은 분류 모델은 모델 성능 평가를 잘 해야 한다.

- 다항 로지스틱 회귀분석
  - 종속변수의 범주가 3개 이상일 경우에 사용하는 분석으로서, 이항 로지스틱과 방법이 크게 다르지 않다.
  - 범주는 여러 개일지라도 각 범주마다 이항 로지스틱을 시행하여 확률을 구하기 때문이다.
  - 종속변수의 모든 범주에 해당하는 확률의 합을 100%로 한다. 그리고 범주들 간에 확률이 어느 것이 더 큰지를 알아야 하기 때문에 하나의 범주를 기준으로 잡는다. 
  - 예시
    - 종속변수의 범주가 4개라면, 이 중 하나의 범주를 기준으로 잡고 나머지 다른 범주들과 비교해서 식을 만든다.
    - 범주가 네 개이면 식은 세 개가 나오는데, 이유는 1에서 세 범주의 확률을 뺀 나머지가 곧 해당 나타나지 않은 범주의 확률이 되기 때문이다.
  - 그래서 다항 로지스틱 회귀분석은 이항 로지스틱 식이 K-1개가 필요하다. 

- 결과 해석
  - 선형 회귀분석 모형 결과와 차이가 있다면, 각 변수의 오즈비를 알 수 있다는 것이다.
  - 로지스틱 회귀분석도 결정계수 값이 산출되는데, 선형회귀처럼 연속형 값에 대한 분산이 있는 것은 아니기 때문에 좀 다른 방식으로 구한다. 다만, 공식적으로 알려진 방식이 10가지가 넘어 딱히 대표적인 방법이 없다.

## 13.8. k-means 클러스터링(군집모델)
<!-- 새롭게 배운 내용을 자유롭게 정리해주세요.-->
- K-means 클러스터링 개요
  - K-means 클러스터링 분석방법은 KNN과 비슷하면서도 전혀 다른 모델이다. 우선 KNN은 지도 학습이고 K-means 클러스터링은 비지도 학습이다. 
  - Clustering(군집화)는 기업에서 수행하는 고객 세그먼트 분석과 유사하다.
    - 예를 들어 성별, 연령, 지역, 구매 패턴 등의 특성이 비슷한 고객들끼리 묶어서 군집으로 분류하고 분류된 군집에 맞게 마케팅 전략을 수립하는 것이다.

- K-means 클러스터링의 진행 단계
  - 구성요소와 그 의미
    - K는 분류할 군집의 수를 뜻한다. 
    - Means는 각 군집의 중심(Centroid)를 의미한다.
      - 군집의 중심점을 각 관측치들 간의 거리 평균값으로 구하기 때문이다.
    - 중심점과 군집 내 관측치 간의 거리를 비용함수로 하여, 이 값이 최소화되도록 중심점과 군집을 반복적으로 재정의해 준다. 
    - 이 역시 관측치와 중심점 간의 거리를 이용하기 때문에 데이터 표준화나 정규화를 꼭 해주어야 한다.
  - 진행 단계
    1. k개의 중심점을 임의의 데이터 공간에 선정
    2. 각 중심점과 관측치들 간의 유클리드 거리를 계산
    3. 각 중심점과 거리가 가까운 관측치들을 해당 군집으로 할당
    4. 할당된 군집의 관측치들과 해당 중싲멈들과의 유클리드 거리를 계산
    5. 중심점을 군집의 중앙으로 이동(군집의 관측치들 간 거리 최소 지점)
    6. 중심점이 더 이상 이동하지 않을 때까지 2~5단계를 반복 

- K-means 클러스터링의 단점
  - k-means 클러스터링은 중심점과 군집 내 관측치 간의 거리를 비용함수로 하여, 이 함수 값이 최소화되도록 중심점과 군집을 반복적으로 재정의해 준다.
  - 따라서, 정말로 거리합이 최소화 되는 전역 최솟값을 찾기 전에 지역 최솟값에서 알고리즘이 종료되는 것이다. 이러한 지역 최솟값 문제를 방지하기 위해 초기 중심점 선정 방법을 다양하게 하여 최적의 모델을 선정할 수 있다.
    - 랜덤 방식
    - 중심점들을 가능한 서로 멀리 떨어져 설정하는 방법
    - k-means++<br>: 무작위 선택된 첫 번째 중심점에서 멀리 있는 데이터 포인트가 높은 확률로 다음 중심점으로 선택되도록 가중치(비례 확률)를 적용하여 중심점들을 생성하는 방법이다.

- 적절한 K 수의 선정
  1. 비즈니스 도메인 지식을 통한 개수 선정
  2. 엘보우 기법<br>: 군집 내 중심점과 관측치 간 거리 합이 급감하는 구간의 k 개수를 선정하는 방법이다. 군집의 수가 k개였을 때보다 k+1개일 때 거리합이 급감했다는 것은 유사한 속성의 관측치들끼리 잘 묶였다는 것을 뜻한다. 따라서 k가 더 증가해도 거리합이 별로 줄어들지 않을 때는 k를 더 증가시킬 필요가 없다는 것을 의미한다.
  3. 실루엣 계수 활용<br>: 실루엣 계수는 군집 안의 관측치들이 다른 군집과 비교해서 얼마나 비슷한지를 나타내는 수치다. 동일한 군집 안에 있는 관측치들 간의 평균 거리와 가장 가까운 다른 군집과의 평균 거리를 구해 실루엣 계수를 구한다. 

# 14. 모델 평가

```
✅ 학습 목표 :
* 유의확률(p-value)을 해석할 때 주의할 점을 설명할 수 있다.
* 분석가가 올바른 주관적 판단을 위한 필수 요소를 식별할 수 있다.
```

## 14.3. 회귀성능 평가지표
<!-- 새롭게 배운 내용을 자유롭게 정리해주세요.-->

## 14.6. 유의확률의 함정
<!-- 새롭게 배운 내용을 자유롭게 정리해주세요.-->

## 14.7. 분석가의 주관적 판단과 스토리텔링
<!-- 새롭게 배운 내용을 자유롭게 정리해주세요.-->


<br>
<br>

# 확인 문제

## **문제 1. 선형 회귀**

> **🧚 칼 피어슨의 아버지와 아들의 키 연구 결과를 바탕으로, 다음 선형 회귀식을 해석하세요.**  
> 칼 피어슨(Karl Pearson)은 아버지(X)와 아들(Y)의 키를 조사한 결과를 바탕으로 아래와 같은 선형 회귀식을 도출하였습니다. 아래의 선형 회귀식을 보고 기울기의 의미를 설명하세요. 
>  
> **ŷ = 33.73 + 0.516X**  
>   
> - **X**: 아버지의 키 (cm)  
> - **ŷ**: 아들의 예상 키 (cm)  

```
아버지의 키가 특정 값을 가질 때, 아들의 키는 해당 키의 0.516배가 된다.
```
---

## **문제 2. 로지스틱 회귀**  

> **🧚 다트비에서는 학생의 학업 성취도를 예측하기 위해 다항 로지스틱 회귀 분석을 수행하였습니다. 학업 성취도(Y)는 ‘낮음’, ‘보통’, ‘높음’ 3가지 범주로 구분되며, 독립 변수는 주당 공부 시간(Study Hours)과 출석률(Attendance Rate)입니다. 단, 기준범주는 '낮음' 입니다.**   

| 변수 | Odds Ratio Estimates | 95% Wald Confidence Limits |  
|------|----------------------|--------------------------|  
| Study Hours | **2.34** | (1.89, 2.88) |  
| Attendance Rate | **3.87** | (2.92, 5.13) |  

> 🔍 Q1. Odds Ratio Estimates(오즈비, OR)의 의미를 해석하세요.

<!--변수 Study Hours의 오즈비 값이 2.34라는 것과 Attendance Rate의 오즈비 값이 3.87이라는 것이 각각 무엇을 의미하는지 구체적으로 생각해보세요.-->

```
공부시간이 1시간 증가할수록 성취도가 '보통'이 될 확률이 2.34배 증가하고, 
Attendance Rate이 1 증가할수록 성취도가 '보통'이 될 확률이 3.87배 증가한다는 의미이다.
```

> 🔍 Q2. 95% Wald Confidence Limits의 의미를 설명하세요.
<!--각 변수의 신뢰구간에 제시된 수치가 의미하는 바를 생각해보세요.-->

```
여기에 답을 작성해주세요!
```

> 🔍 Q3. 이 분석을 기반으로 학업 성취도를 향상시키기 위한 전략을 제안하세요.
<!--Study Hours와 Attendance Rate 중 어느 변수가 학업 성취도에 더 큰 영향을 미치는지를 고려하여, 학업 성취도를 향상시키기 위한 효과적인 전략을 구체적으로 제시해보세요.-->

```
공부 시간과 출석을 모두 높일 수 있으면 좋겠지만,
어렵다면 우선 출석률을 높이는 것을 목표로 하여 전략을 구성한다.
```

---


## **문제 3. k-means 클러스터링**

> **🧚 선교는 고객을 유사한 그룹으로 분류하기 위해 k-means 클러스터링을 적용했습니다. 초기에는 3개의 군집으로 설정했지만, 결과가 만족스럽지 않았습니다. 선교가 최적의 군집 수를 찾기 위해 사용할 수 있는 방법을 한 가지 이상 제시하고 설명하세요.**

```
2. 엘보우 기법
: 군집 내 중심점과 관측치 간 거리 합이 급감하는 구간의 k 개수를 선정하는 방법이다.
3. 실루엣 계수 활용
: 군집 안의 관측치들이 다른 군집과 비교해서 얼마나 비슷한지를 나타내는 수치다. 
동일한 군집 안에 있는 관측치들 간의 평균 거리와 가장 가까운 다른 군집과의 평균 거리를 구해 실루엣 계수를 구한다. 
실루엣 계수가 1에 가까울수록 k수가 적합하게 나누어졌음을 의미한다.
```

### 🎉 수고하셨습니다.